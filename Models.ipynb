{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"Datasets/Encoded_data_without_PCA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the orginal non-one-hot-encoding columns\n",
    "non_ohe_columns = ['Unnamed: 0', 'BoRace', 'BoGender', 'PropType', 'AcqTyp', 'FedGuar', 'BoEth']\n",
    "BoRace_col = df['BoRace']\n",
    "df = df.drop(non_ohe_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_results(model, y_train, y_pred_train, y_test, y_pred_test):\n",
    "    print(model, \"Training Results & Evaluation:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_train,y_pred_train))\n",
    "    print(classification_report(y_train,y_pred_train))\n",
    "    print()\n",
    "    print(model, \"Testing Results & Evaluation:\")\n",
    "    print()\n",
    "    print(confusion_matrix(y_test,y_pred_test))\n",
    "    print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification for BoRace\n",
    "\n",
    "# Creating the dataset for BoEth Class Prediction\n",
    "df_BoRace = df\n",
    "\n",
    "df_BoRace['BoRace'] = BoRace_col\n",
    "\n",
    "# Removing one-hot-encoding values for BoRace\n",
    "df_BoRace = df_BoRace.drop(['BoRace_2', 'BoRace_5'], axis = 1)\n",
    "\n",
    "for col in df_BoRace.columns:\n",
    "    df_BoRace[col] = df_BoRace[col].astype(float)\n",
    "    \n",
    "# Encoding (White)5 = > 0, (Non-White)1,2,3,4 => 1    \n",
    "df_BoRace['BoRace'] = df_BoRace['BoRace'].astype(int)\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 5, 0, df_BoRace['BoRace'])\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 2, 1, df_BoRace['BoRace'])\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 3, 1, df_BoRace['BoRace'])\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 4, 1, df_BoRace['BoRace'])                             \n",
    "\n",
    "# Spliting the dataset for training & testing\n",
    "X = df_BoRace.iloc[:, :-1].values\n",
    "y = df_BoRace.iloc[:, -1:].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Results & Evaluation:\n",
      "\n",
      "[[30787   201]\n",
      " [ 2260   455]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     30988\n",
      "           1       0.69      0.17      0.27      2715\n",
      "\n",
      "    accuracy                           0.93     33703\n",
      "   macro avg       0.81      0.58      0.62     33703\n",
      "weighted avg       0.91      0.93      0.91     33703\n",
      "\n",
      "\n",
      "XGBoost Testing Results & Evaluation:\n",
      "\n",
      "[[13185   101]\n",
      " [  989   170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     13286\n",
      "           1       0.63      0.15      0.24      1159\n",
      "\n",
      "    accuracy                           0.92     14445\n",
      "   macro avg       0.78      0.57      0.60     14445\n",
      "weighted avg       0.91      0.92      0.90     14445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the race, using XG Boosting\n",
    "BoRace_XGB_Model = XGBClassifier(objective='multi:softmax', num_class = len(df_BoRace['BoRace'].unique()), random_state = 0)\n",
    "BoRace_XGB_Model.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred_train = BoRace_XGB_Model.predict(X_train)\n",
    "y_pred_test = BoRace_XGB_Model.predict(X_test)\n",
    "\n",
    "# Model Evaluations\n",
    "print_classification_results(\"XGBoost\", y_train, y_pred_train, y_test, y_pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Training Results & Evaluation:\n",
      "\n",
      "[[30794   194]\n",
      " [ 1056  1659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     30988\n",
      "           1       0.90      0.61      0.73      2715\n",
      "\n",
      "    accuracy                           0.96     33703\n",
      "   macro avg       0.93      0.80      0.85     33703\n",
      "weighted avg       0.96      0.96      0.96     33703\n",
      "\n",
      "\n",
      "Neural Network Testing Results & Evaluation:\n",
      "\n",
      "[[12823   463]\n",
      " [  849   310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     13286\n",
      "           1       0.40      0.27      0.32      1159\n",
      "\n",
      "    accuracy                           0.91     14445\n",
      "   macro avg       0.67      0.62      0.64     14445\n",
      "weighted avg       0.89      0.91      0.90     14445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the race, using Neural Networks\n",
    "BoRace_NN_Model = MLPClassifier(hidden_layer_sizes=(128, 64, 8), activation='relu', solver='adam', \\\n",
    "                                learning_rate = 'constant', alpha = 0.00001, max_iter = 20000, random_state = 0)\n",
    "BoRace_NN_Model.out_activation_ = 'softmax'\n",
    "BoRace_NN_Model.fit(X_train,y_train.ravel())\n",
    "\n",
    "y_pred_train = BoRace_NN_Model.predict(X_train)\n",
    "y_pred_test = BoRace_NN_Model.predict(X_test)\n",
    "\n",
    "# Model Evaluations\n",
    "print_classification_results(\"Neural Network\", y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df_pca = pd.read_csv(\"Datasets/Encoded_data_with_PCA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification for BoRace\n",
    "\n",
    "# Creating the dataset after PCA for BoEth Class Prediction\n",
    "df_BoRace = df_pca.dropna()\n",
    "\n",
    "# Encoding (White)5 = > 0, (Non-White)1,2,3,4 => 1 \n",
    "# Column 12 is BoRace Column\n",
    "df_BoRace['12'] = np.where(df_BoRace['12'] == 5.0, 0.0, df_BoRace['12'])\n",
    "df_BoRace['12'] = np.where(df_BoRace['12'] == 2.0, 1.0, df_BoRace['12'])\n",
    "df_BoRace['12'] = np.where(df_BoRace['12'] == 3.0, 1.0, df_BoRace['12'])\n",
    "df_BoRace['12'] = np.where(df_BoRace['12'] == 4.0, 1.0, df_BoRace['12']) \n",
    "#df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'].isnull(), 1.0, df_BoRace['BoRace']) \n",
    "\n",
    "X = df_BoRace.iloc[:, :-1].values\n",
    "y = df_BoRace.iloc[:, -1:].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Results & Evaluation:\n",
      "\n",
      "[[30741   247]\n",
      " [ 2221   494]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     30988\n",
      "         1.0       0.67      0.18      0.29      2715\n",
      "\n",
      "    accuracy                           0.93     33703\n",
      "   macro avg       0.80      0.59      0.62     33703\n",
      "weighted avg       0.91      0.93      0.91     33703\n",
      "\n",
      "\n",
      "XGBoost Testing Results & Evaluation:\n",
      "\n",
      "[[13179   107]\n",
      " [  945   214]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96     13286\n",
      "         1.0       0.67      0.18      0.29      1159\n",
      "\n",
      "    accuracy                           0.93     14445\n",
      "   macro avg       0.80      0.59      0.63     14445\n",
      "weighted avg       0.91      0.93      0.91     14445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the race, using XG Boosting\n",
    "BoRace_XGB_Model = XGBClassifier(objective='multi:softmax', num_class = len(df_BoRace['12'].unique()), random_state = 0)\n",
    "BoRace_XGB_Model.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred_train = BoRace_XGB_Model.predict(X_train)\n",
    "y_pred_test = BoRace_XGB_Model.predict(X_test)\n",
    "\n",
    "# Model Evaluations\n",
    "print_classification_results(\"XGBoost\", y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Training Results & Evaluation:\n",
      "\n",
      "[[30584   404]\n",
      " [ 2077   638]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96     30988\n",
      "         1.0       0.61      0.23      0.34      2715\n",
      "\n",
      "    accuracy                           0.93     33703\n",
      "   macro avg       0.77      0.61      0.65     33703\n",
      "weighted avg       0.91      0.93      0.91     33703\n",
      "\n",
      "\n",
      "Neural Network Testing Results & Evaluation:\n",
      "\n",
      "[[13104   182]\n",
      " [  891   268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96     13286\n",
      "         1.0       0.60      0.23      0.33      1159\n",
      "\n",
      "    accuracy                           0.93     14445\n",
      "   macro avg       0.77      0.61      0.65     14445\n",
      "weighted avg       0.91      0.93      0.91     14445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predicting the race, using Neural Networks\n",
    "BoRace_NN_Model = MLPClassifier(hidden_layer_sizes=(32,4), activation='relu', solver='adam', \\\n",
    "                                learning_rate = 'constant', alpha = 0.00001, max_iter = 20000, random_state = 0)\n",
    "BoRace_NN_Model.out_activation_ = 'softmax'\n",
    "BoRace_NN_Model.fit(X_train,y_train.ravel())\n",
    "\n",
    "y_pred_train = BoRace_NN_Model.predict(X_train)\n",
    "y_pred_test = BoRace_NN_Model.predict(X_test)\n",
    "\n",
    "# Model Evaluations\n",
    "print_classification_results(\"Neural Network\", y_train, y_pred_train, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
