{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Scaling using .quantile() Pandas methods\n",
    "def scale_outlier(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    min_bound = Q1 - 1.5*IQR\n",
    "    max_bound = Q3 + 1.5*IQR\n",
    "    df[column] = np.where(df[column] > max_bound, max_bound, df[column])\n",
    "    df[column] = np.where(df[column] < min_bound, min_bound, df[column])\n",
    "\n",
    "# Min-Max Scaling using .min() and .max() Pandas methods\n",
    "def min_max_scaling(df):    \n",
    "    df_norm = df.copy()\n",
    "    for column in df_norm.columns:\n",
    "        df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())        \n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Cleaned_data.csv\")\n",
    "categorical_cols = ['BoRace', 'CoRace', 'BoGender',\\\n",
    "                                      'CoGender', 'Geog', 'BoCreditScor',\\\n",
    "                                      'CoBoCreditScor', 'PropType', 'BoEth',\\\n",
    "                                      'CoEth', 'SpcHsgGoals', 'AcqTyp', 'Bank',\\\n",
    "                                      'FedGuar', 'First', 'Self', 'NumBor']\n",
    "numerical_cols = ['BoAge', 'CoAge','MSA', 'MinPer', 'LocMedY', 'Tractrat', 'Income',\\\n",
    "                 'IncRat', 'UPB', 'LTV', 'Term', 'Rate', 'Front','Back', 'PMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding - Convert categorical columns to One hot encoding\n",
    "df = pd.get_dummies(df, columns = categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise numerical columns and add it to the dataset\n",
    "scale_columns = min_max_scaling(df[numerical_cols])\n",
    "df = df.drop(numerical_cols, axis = 1)\n",
    "df = pd.concat([df, scale_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop one hot encoded columns that have values in less than 5% of total number of rows or more than 95% of rows\n",
    "oheEncodedCols = ['BoRace_1', 'BoRace_2', 'BoRace_3', 'BoRace_4', 'BoRace_5', 'BoRace_7', \\\n",
    "                  'CoRace_1', 'CoRace_2', 'CoRace_3', 'CoRace_4', 'CoRace_5', 'CoRace_7', 'CoRace_8',\\\n",
    "                  'BoGender_1', 'BoGender_2', 'BoGender_3', 'CoGender_1', 'CoGender_2' , 'CoGender_3', 'CoGender_4',\\\n",
    "                  'BoCreditScor_1', 'BoCreditScor_2', 'BoCreditScor_3', 'BoCreditScor_4', 'BoCreditScor_5', 'BoCreditScor_9', \\\n",
    "                  'CoBoCreditScor_1', 'CoBoCreditScor_2', 'CoBoCreditScor_3', 'CoBoCreditScor_4', 'CoBoCreditScor_5', \\\n",
    "                  'CoBoCreditScor_9', 'BoEth_1', 'BoEth_2', 'BoEth_3', 'CoEth_1', 'CoEth_2', 'CoEth_3', 'CoEth_5',\\\n",
    "                  'Geog_1', 'Geog_2', 'PropType_PT01', 'PropType_PT02', 'PropType_PT04', 'PropType_PT06', 'PropType_PT07',\\\n",
    "                  'PropType_PT09', 'PropType_PT10', 'PropType_PT11', 'PropType_PT12', 'SpcHsgGoals_1', 'SpcHsgGoals_2',\\\n",
    "                  'AcqTyp_1', 'AcqTyp_4', 'Bank_Atlanta', 'Bank_Boston', 'Bank_Chicago', 'Bank_Cincinnati', 'Bank_Dallas',\\\n",
    "                  'Bank_Des Moines', 'Bank_Indianapolis', 'Bank_New York', 'Bank_Pittsburgh', 'Bank_San Francisco', \\\n",
    "                  'Bank_Topeka', 'FedGuar_0', 'FedGuar_1', 'FedGuar_2', 'FedGuar_3', 'First_1', 'First_2', 'Self_1',\\\n",
    "                  'Self_2', 'NumBor_1', 'NumBor_2', 'NumBor_3', 'NumBor_4',]\n",
    "for val in oheEncodedCols:\n",
    "  filteredLen = df[df[val] == 1].count()[0]\n",
    "  datasetLen = df.count()[0]\n",
    "  if( filteredLen < 0.05 * datasetLen and filteredLen > 0.95 * datasetLen):\n",
    "    df = df.drop([val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Assigned.ID', axis = 1)\n",
    "df = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.313 0.071 0.064 0.057 0.053 0.046 0.035 0.032 0.025 0.024 0.023 0.019\n",
      " 0.018 0.016 0.015 0.013 0.012 0.011 0.01  0.01  0.009 0.008 0.008 0.008\n",
      " 0.007 0.007 0.006 0.006 0.006 0.005]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "df_pca = pca.fit_transform(df)\n",
    "\n",
    "# Store as dataframe and print\n",
    "df_pca = pd.DataFrame(df_pca)\n",
    "df_pca.round(10).head()\n",
    "\n",
    "print(pca.explained_variance_ratio_.round(3)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "total_variance = 0\n",
    "required_col = 0\n",
    "for i in pca.explained_variance_ratio_:\n",
    "    total_variance += i\n",
    "    required_col += 1\n",
    "    if total_variance > 0.9:\n",
    "        break\n",
    "print(required_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df_pca[0:25]\n",
    "df_pca.to_csv(r'Encoded_data_with_PCA.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
