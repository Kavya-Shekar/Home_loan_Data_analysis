{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(\"Datasets/Encoded_data_without_PCA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the orginal non-one-hot-encoding columns\n",
    "non_ohe_columns = ['Unnamed: 0', 'BoRace', 'BoGender', 'PropType', 'AcqTyp', 'FedGuar', 'BoEth']\n",
    "BoRace_col = df['BoRace']\n",
    "df = df.drop(non_ohe_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification for BoRace\n",
    "\n",
    "# Creating the dataset for BoEth Class Prediction\n",
    "df_BoRace = df\n",
    "\n",
    "df_BoRace['BoRace'] = BoRace_col\n",
    "\n",
    "# Removing one-hot-encoding values for BoRace\n",
    "df_BoRace = df_BoRace.drop(['BoRace_2', 'BoRace_5'], axis = 1)\n",
    "\n",
    "for col in df_BoRace.columns:\n",
    "    df_BoRace[col] = df_BoRace[col].astype(float)\n",
    "    \n",
    "# Encoding (White)5 = > 0, (Non-White)1,2,3,4 => 1    \n",
    "df_BoRace['BoRace'] = df_BoRace['BoRace'].astype(int)\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 5, 0, df_BoRace['BoRace'])\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 2, 1, df_BoRace['BoRace'])\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 3, 1, df_BoRace['BoRace'])\n",
    "df_BoRace['BoRace'] = np.where(df_BoRace['BoRace'] == 4, 1, df_BoRace['BoRace'])                             \n",
    "\n",
    "X = df_BoRace.iloc[:, :-1].values\n",
    "y = df_BoRace.iloc[:, -1:].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(df_BoRace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the race, using XG Boosting Algorithm\n",
    "BoRace_XGB_Model = XGBClassifier(objective='multi:softmax', num_class = len(df_BoRace['BoRace'].unique()), random_state = 0)\n",
    "BoRace_XGB_Model.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred_train = BoRace_XGB_Model.predict(X_train)\n",
    "y_pred_test = BoRace_XGB_Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30787   201]\n",
      " [ 2260   455]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     30988\n",
      "           1       0.69      0.17      0.27      2715\n",
      "\n",
      "    accuracy                           0.93     33703\n",
      "   macro avg       0.81      0.58      0.62     33703\n",
      "weighted avg       0.91      0.93      0.91     33703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XG Boost Train Results\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13185   101]\n",
      " [  989   170]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     13286\n",
      "           1       0.63      0.15      0.24      1159\n",
      "\n",
      "    accuracy                           0.92     14445\n",
      "   macro avg       0.78      0.57      0.60     14445\n",
      "weighted avg       0.91      0.92      0.90     14445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XG Boost Test Results\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the race, using XG Boosting Algorithm\n",
    "BoRace_NN_Model = MLPClassifier(hidden_layer_sizes=(64,8), activation='relu', solver='adam', \\\n",
    "                                learning_rate = 'constant', alpha = 0.00001, max_iter = 20000, random_state = 0)\n",
    "BoRace_NN_Model.out_activation_ = 'softmax'\n",
    "BoRace_NN_Model.fit(X_train,y_train.ravel())\n",
    "\n",
    "y_pred_train = BoRace_NN_Model.predict(X_train)\n",
    "y_pred_test = BoRace_NN_Model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30794   194]\n",
      " [ 1056  1659]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98     30988\n",
      "           1       0.90      0.61      0.73      2715\n",
      "\n",
      "    accuracy                           0.96     33703\n",
      "   macro avg       0.93      0.80      0.85     33703\n",
      "weighted avg       0.96      0.96      0.96     33703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NN Train Results\n",
    "print(confusion_matrix(y_train,y_pred_train))\n",
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12823   463]\n",
      " [  849   310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95     13286\n",
      "           1       0.40      0.27      0.32      1159\n",
      "\n",
      "    accuracy                           0.91     14445\n",
      "   macro avg       0.67      0.62      0.64     14445\n",
      "weighted avg       0.89      0.91      0.90     14445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NN Test Results\n",
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
